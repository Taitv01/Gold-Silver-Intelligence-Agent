"""
Gold-Silver-Intelligence Agents Module
Rewritten for AgentScope 1.0+ API (async-based).
Supports: Gemini, ZhipuAI (GLM), OpenAI as fallback.
"""
import os
import asyncio
import requests
import agentscope
from agentscope.agent import ReActAgent
from agentscope.message import Msg
from agentscope.model import GeminiChatModel, OpenAIChatModel, ZhipuAIChatModel
from agentscope.formatter import GeminiChatFormatter, OpenAIChatFormatter, ZhipuAIChatFormatter
from agentscope.memory import InMemoryMemory
from agentscope.tool import Toolkit

from src.config import SERPER_API_KEY, GEMINI_API_KEY, OPENAI_API_KEY, GLM_API_KEY


def search_news(query: str, num_results: int = 10) -> list:
    """
    Search for news using Serper API.

    Args:
        query: Search query string
        num_results: Number of results to return

    Returns:
        List of news articles with title, link, snippet
    """
    if not SERPER_API_KEY:
        print("[ERROR] SERPER_API_KEY not configured.")
        return []

    url = "https://google.serper.dev/news"
    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "q": query,
        "num": num_results,
        "tbs": "qdr:d"  # Last 24 hours
    }

    try:
        response = requests.post(url, json=payload, headers=headers, timeout=15)
        response.raise_for_status()
        data = response.json()

        news = []
        for item in data.get("news", []):
            news.append({
                "title": item.get("title", ""),
                "link": item.get("link", ""),
                "snippet": item.get("snippet", ""),
                "source": item.get("source", ""),
                "date": item.get("date", "")
            })
        return news

    except requests.exceptions.RequestException as e:
        print(f"[ERROR] Serper API request failed: {e}")
        return []


# === Agent System Prompts ===

NEWS_HUNTER_PROMPT = """B·∫°n l√† NewsHunter - chuy√™n gia thu th·∫≠p v√† l·ªçc tin t·ª©c th·ªã tr∆∞·ªùng V√†ng/B·∫°c.

NHI·ªÜM V·ª§:
1. Ph√¢n t√≠ch c√°c tin t·ª©c ƒë∆∞·ª£c cung c·∫•p
2. L·ªçc ra c√°c tin quan tr·ªçng li√™n quan ƒë·∫øn:
   - Ch√≠nh s√°ch l√£i su·∫•t Fed/FOMC
   - Chi·∫øn tranh, xung ƒë·ªôt ƒë·ªãa ch√≠nh tr·ªã
   - Ch·ªâ s·ªë DXY (USD Index)
   - L·∫°m ph√°t, CPI, vi·ªác l√†m M·ªπ
   - Ch√≠nh s√°ch ti·ªÅn t·ªá c√°c ng√¢n h√†ng trung ∆∞∆°ng l·ªõn

OUTPUT FORMAT:
üì∞ **TIN T·ª®C QUAN TR·ªåNG**

1. [Ti√™u ƒë·ªÅ tin 1]
   - Ngu·ªìn: [source]
   - T√≥m t·∫Øt: [2-3 c√¢u t√≥m t·∫Øt]

2. [Ti√™u ƒë·ªÅ tin 2]
   ...

N·∫øu kh√¥ng c√≥ tin quan tr·ªçng, tr·∫£ v·ªÅ: "Kh√¥ng c√≥ tin ƒë√°ng ch√∫ √Ω trong 24h qua."
"""

MARKET_ANALYST_PROMPT = """B·∫°n l√† MarketAnalyst - chuy√™n gia ph√¢n t√≠ch t√°c ƒë·ªông tin t·ª©c l√™n gi√° V√†ng/B·∫°c.

NHI·ªÜM V·ª§:
D·ª±a tr√™n tin t·ª©c ƒë∆∞·ª£c cung c·∫•p, ph√¢n t√≠ch xu h∆∞·ªõng gi√° V√†ng/B·∫°c.

PH∆Ø∆†NG PH√ÅP PH√ÇN T√çCH:
- Fed hawkish (tƒÉng l√£i su·∫•t) ‚Üí Bearish cho V√†ng/B·∫°c
- Fed dovish (gi·ªØ/gi·∫£m l√£i su·∫•t) ‚Üí Bullish cho V√†ng/B·∫°c
- DXY tƒÉng ‚Üí Bearish cho V√†ng/B·∫°c
- DXY gi·∫£m ‚Üí Bullish cho V√†ng/B·∫°c
- B·∫•t ·ªïn ƒë·ªãa ch√≠nh tr·ªã ‚Üí Bullish (safe haven)
- L·∫°m ph√°t cao ‚Üí Bullish (hedge)

OUTPUT FORMAT:
üìä **PH√ÇN T√çCH TH·ªä TR∆Ø·ªúNG V√ÄNG/B·∫†C**

üîπ **Xu h∆∞·ªõng V√†ng (XAU/USD):** [BULLISH/BEARISH/NEUTRAL]
üîπ **Xu h∆∞·ªõng B·∫°c (XAG/USD):** [BULLISH/BEARISH/NEUTRAL]

**L√Ω do:**
[Gi·∫£i th√≠ch ng·∫Øn g·ªçn 3-5 ƒëi·ªÉm ch√≠nh]

**Khuy·∫øn ngh·ªã:**
[G·ª£i √Ω h√†nh ƒë·ªông: Mua/B√°n/Quan s√°t]

‚ö†Ô∏è *ƒê√¢y l√† ph√¢n t√≠ch tham kh·∫£o, kh√¥ng ph·∫£i t∆∞ v·∫•n ƒë·∫ßu t∆∞.*
"""


def get_model_and_formatter():
    """
    Get the appropriate model and formatter based on available API keys.
    Priority: Gemini -> GLM (ZhipuAI) -> OpenAI
    """
    # Priority 1: Gemini
    if GEMINI_API_KEY:
        print("[INFO] Using Gemini API (gemini-2.0-flash)")
        model = GeminiChatModel(
            model_name="gemini-2.0-flash",
            api_key=GEMINI_API_KEY,
        )
        formatter = GeminiChatFormatter()
        return model, formatter
    
    # Priority 2: ZhipuAI (GLM)
    if GLM_API_KEY:
        print("[INFO] Using ZhipuAI GLM API (glm-4-flash)")
        model = ZhipuAIChatModel(
            model_name="glm-4-flash",
            api_key=GLM_API_KEY,
        )
        formatter = ZhipuAIChatFormatter()
        return model, formatter
    
    # Priority 3: OpenAI
    if OPENAI_API_KEY:
        print("[INFO] Using OpenAI API (gpt-4o-mini)")
        model = OpenAIChatModel(
            model_name="gpt-4o-mini",
            api_key=OPENAI_API_KEY,
        )
        formatter = OpenAIChatFormatter()
        return model, formatter
    
    raise ValueError("No LLM API key configured. Set GEMINI_API_KEY, GLM_API_KEY, or OPENAI_API_KEY.")


def get_model_and_formatter_with_fallback():
    """
    Try to get model with automatic fallback if primary fails.
    Tries: Gemini -> GLM -> OpenAI
    """
    errors = []
    
    # Try Gemini first
    if GEMINI_API_KEY:
        try:
            print("[INFO] Trying Gemini API...")
            model = GeminiChatModel(
                model_name="gemini-2.0-flash",
                api_key=GEMINI_API_KEY,
            )
            formatter = GeminiChatFormatter()
            return model, formatter, "Gemini"
        except Exception as e:
            errors.append(f"Gemini: {e}")
            print(f"[WARN] Gemini failed: {e}")
    
    # Fallback to GLM
    if GLM_API_KEY:
        try:
            print("[INFO] Trying ZhipuAI GLM API...")
            model = ZhipuAIChatModel(
                model_name="glm-4-flash",
                api_key=GLM_API_KEY,
            )
            formatter = ZhipuAIChatFormatter()
            return model, formatter, "GLM"
        except Exception as e:
            errors.append(f"GLM: {e}")
            print(f"[WARN] GLM failed: {e}")
    
    # Fallback to OpenAI
    if OPENAI_API_KEY:
        try:
            print("[INFO] Trying OpenAI API...")
            model = OpenAIChatModel(
                model_name="gpt-4o-mini",
                api_key=OPENAI_API_KEY,
            )
            formatter = OpenAIChatFormatter()
            return model, formatter, "OpenAI"
        except Exception as e:
            errors.append(f"OpenAI: {e}")
            print(f"[WARN] OpenAI failed: {e}")
    
    raise ValueError(f"All LLM APIs failed. Errors: {errors}")


async def run_analysis_async(query: str = "gold silver price news") -> str:
    """
    Run the full analysis pipeline (async version).

    Args:
        query: Search query for news

    Returns:
        Final analysis report as string
    """
    print(f"[INFO] Starting analysis pipeline with query: {query}")

    # Step 1: Search for news
    print("[INFO] Fetching news from Serper API...")
    news_items = search_news(query)

    if not news_items:
        return "‚ùå Kh√¥ng t√¨m th·∫•y tin t·ª©c n√†o. Vui l√≤ng th·ª≠ l·∫°i sau."

    # Format news for agent
    news_text = "\n\n".join([
