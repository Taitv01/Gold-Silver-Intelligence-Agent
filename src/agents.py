"""
Gold-Silver-Intelligence Agents Module
Rewritten for AgentScope 1.0+ API (async-based).
Supports: Gemini (primary), OpenAI-compatible APIs (fallback)
Includes: Rate limit handling with retry logic
"""
import os
import time
import asyncio
import requests
from openai import OpenAI
import agentscope
from agentscope.agent import ReActAgent
from agentscope.message import Msg
from agentscope.model import GeminiChatModel, OpenAIChatModel
from agentscope.formatter import GeminiChatFormatter, OpenAIChatFormatter
from agentscope.memory import InMemoryMemory
from agentscope.tool import Toolkit

from src.config import SERPER_API_KEY, GEMINI_API_KEY, OPENAI_API_KEY, GLM_API_KEY, PERPLEXITY_API_KEY


# === Rate Limit Configuration ===
MAX_RETRIES = 3
RETRY_DELAY_SECONDS = 5
RATE_LIMIT_CODES = [429, 503]


def search_news(query: str, num_results: int = 10) -> list:
    """
    Search for news using Serper API with retry logic.

    Args:
        query: Search query string
        num_results: Number of results to return

    Returns:
        List of news articles with title, link, snippet
    """
    if not SERPER_API_KEY:
        print("[ERROR] SERPER_API_KEY not configured.")
        return []

    url = "https://google.serper.dev/news"
    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "q": query,
        "num": num_results,
        "tbs": "qdr:d"  # Last 24 hours
    }

    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=15)
            
            # Handle rate limiting
            if response.status_code in RATE_LIMIT_CODES:
                if attempt < MAX_RETRIES - 1:
                    wait_time = RETRY_DELAY_SECONDS * (attempt + 1)
                    print(f"[WARN] Rate limited (attempt {attempt + 1}/{MAX_RETRIES}), waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"[ERROR] Rate limit exceeded after {MAX_RETRIES} attempts")
                    return []
            
            response.raise_for_status()
            data = response.json()

            news = []
            seen_titles = set()  # Theo dÃµi tiÃªu Ä‘á» Ä‘Ã£ xem
            seen_links = set()   # Theo dÃµi liÃªn káº¿t Ä‘Ã£ xem
            
            for item in data.get("news", []):
                title = item.get("title", "")
                link = item.get("link", "")
                
                # Chuáº©n hÃ³a tiÃªu Ä‘á» Ä‘á»ƒ so sÃ¡nh (chá»¯ thÆ°á»ng, xÃ³a khoáº£ng tráº¯ng thá»«a)
                normalized_title = title.lower().strip()
                
                # Bá» qua náº¿u tiÃªu Ä‘á» hoáº·c liÃªn káº¿t Ä‘Ã£ tá»“n táº¡i
                if normalized_title in seen_titles or link in seen_links:
                    print(f"[INFO] Skipping duplicate news: {title[:50]}...")
                    continue
                
                # ThÃªm vÃ o táº­p há»£p Ä‘Ã£ xem
                seen_titles.add(normalized_title)
                seen_links.add(link)
                
                news.append({
                    "title": title,
                    "link": link,
                    "snippet": item.get("snippet", ""),
                    "source": item.get("source", ""),
                    "date": item.get("date", "")
                })
            return news

        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                print(f"[WARN] Request failed (attempt {attempt + 1}/{MAX_RETRIES}): {e}")
                time.sleep(RETRY_DELAY_SECONDS)
            else:
                print(f"[ERROR] Serper API request failed after {MAX_RETRIES} attempts: {e}")
                return []
    
    return []


def search_twitter(query: str, num_results: int = 5) -> list:
    """
    Search for Twitter/X.com posts using Serper API (Google search with site filter).

    Args:
        query: Search query string
        num_results: Number of results to return

    Returns:
        List of Twitter posts with title, link, snippet
    """
    if not SERPER_API_KEY:
        print("[ERROR] SERPER_API_KEY not configured.")
        return []

    url = "https://google.serper.dev/search"
    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }
    # Search Twitter/X.com using site filter
    twitter_query = f"{query} (site:x.com OR site:twitter.com)"
    payload = {
        "q": twitter_query,
        "num": num_results,
        "tbs": "qdr:d"  # Last 24 hours
    }

    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=15)

            if response.status_code in RATE_LIMIT_CODES:
                if attempt < MAX_RETRIES - 1:
                    wait_time = RETRY_DELAY_SECONDS * (attempt + 1)
                    print(f"[WARN] Twitter search rate limited (attempt {attempt + 1}/{MAX_RETRIES}), waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"[ERROR] Twitter search rate limit exceeded after {MAX_RETRIES} attempts")
                    return []

            response.raise_for_status()
            data = response.json()

            tweets = []
            seen_links = set()
            
            for item in data.get("organic", []):
                link = item.get("link", "")
                
                if "x.com" not in link and "twitter.com" not in link:
                    continue
                
                if link in seen_links:
                    continue
                
                seen_links.add(link)
                tweets.append({
                    "title": item.get("title", ""),
                    "link": link,
                    "snippet": item.get("snippet", ""),
                    "source": "X/Twitter",
                    "date": item.get("date", "Gáº§n Ä‘Ã¢y")
                })
            
            print(f"[INFO] Found {len(tweets)} tweets from X/Twitter")
            return tweets

        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                print(f"[WARN] Twitter search failed (attempt {attempt + 1}/{MAX_RETRIES}): {e}")
                time.sleep(RETRY_DELAY_SECONDS)
            else:
                print(f"[ERROR] Twitter search failed after {MAX_RETRIES} attempts: {e}")
                return []

    return []


def search_all_sources(query: str, num_news: int = 8, num_tweets: int = 5) -> list:
    """
    Search for news from all sources: News + Twitter/X.com
    
    Args:
        query: Search query string
        num_news: Number of news articles to fetch
        num_tweets: Number of tweets to fetch
        
    Returns:
        Combined list of news and tweets, deduplicated
    """
    print("[INFO] Fetching news from Serper API...")
    news = search_news(query, num_news)
    
    print("[INFO] Fetching posts from X/Twitter...")
    tweets = search_twitter(query, num_tweets)
    
    # Combine and deduplicate
    all_items = news + tweets
    
    # Sort by source type (news first, then tweets)
    # This ensures variety in results
    print(f"[INFO] Total: {len(news)} news + {len(tweets)} tweets = {len(all_items)} items")
    
    return all_items


# === Agent System Prompts ===

NEWS_HUNTER_PROMPT = """Báº¡n lÃ  NewsHunter - chuyÃªn gia thu tháº­p vÃ  lá»c tin tá»©c thá»‹ trÆ°á»ng VÃ ng/Báº¡c.

NGUá»’N TIN: Báº¡n sáº½ nháº­n Ä‘Æ°á»£c tin tá»©c tá»« nhiá»u nguá»“n:
- Tin tá»©c tá»« cÃ¡c trang bÃ¡o chÃ­nh thá»‘ng
- BÃ i Ä‘Äƒng tá»« X/Twitter (cÃ³ thá»ƒ tá»« cÃ¡c chuyÃªn gia, nhÃ  phÃ¢n tÃ­ch)

NHIá»†M Vá»¤:
1. PhÃ¢n tÃ­ch cÃ¡c tin tá»©c vÃ  bÃ i Ä‘Äƒng Ä‘Æ°á»£c cung cáº¥p
2. Lá»c ra cÃ¡c tin quan trá»ng liÃªn quan Ä‘áº¿n:
   - ChÃ­nh sÃ¡ch lÃ£i suáº¥t Fed/FOMC
   - Chiáº¿n tranh, xung Ä‘á»™t Ä‘á»‹a chÃ­nh trá»‹
   - Chá»‰ sá»‘ DXY (USD Index)
   - Láº¡m phÃ¡t, CPI, viá»‡c lÃ m Má»¹
   - ChÃ­nh sÃ¡ch tiá»n tá»‡ cÃ¡c ngÃ¢n hÃ ng trung Æ°Æ¡ng lá»›n
   - Ã kiáº¿n tá»« cÃ¡c chuyÃªn gia ná»•i tiáº¿ng trÃªn X/Twitter

OUTPUT FORMAT:
ðŸ“° **TIN Tá»¨C QUAN TRá»ŒNG**

1. [TiÃªu Ä‘á» tin 1]
   - Nguá»“n: [source] (Ä‘Ã¡nh dáº¥u ðŸ¦ náº¿u tá»« X/Twitter)
   - TÃ³m táº¯t: [2-3 cÃ¢u tÃ³m táº¯t]

2. [TiÃªu Ä‘á» tin 2]
   ...

Náº¿u khÃ´ng cÃ³ tin quan trá»ng, tráº£ vá»: "KhÃ´ng cÃ³ tin Ä‘Ã¡ng chÃº Ã½ trong 24h qua."
"""

MARKET_ANALYST_PROMPT = """Báº¡n lÃ  MarketAnalyst - chuyÃªn gia phÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng tin tá»©c lÃªn giÃ¡ VÃ ng/Báº¡c.

NHIá»†M Vá»¤:
Dá»±a trÃªn tin tá»©c Ä‘Æ°á»£c cung cáº¥p, phÃ¢n tÃ­ch xu hÆ°á»›ng giÃ¡ VÃ ng/Báº¡c.

PHÆ¯Æ NG PHÃP PHÃ‚N TÃCH:
- Fed hawkish (tÄƒng lÃ£i suáº¥t) â†’ Bearish cho VÃ ng/Báº¡c
- Fed dovish (giá»¯/giáº£m lÃ£i suáº¥t) â†’ Bullish cho VÃ ng/Báº¡c
- DXY tÄƒng â†’ Bearish cho VÃ ng/Báº¡c
- DXY giáº£m â†’ Bullish cho VÃ ng/Báº¡c
- Báº¥t á»•n Ä‘á»‹a chÃ­nh trá»‹ â†’ Bullish (safe haven)
- Láº¡m phÃ¡t cao â†’ Bullish (hedge)

OUTPUT FORMAT:
ðŸ“Š **PHÃ‚N TÃCH THá»Š TRÆ¯á»œNG VÃ€NG/Báº C**

ðŸ”¹ **Xu hÆ°á»›ng VÃ ng (XAU/USD):** [BULLISH/BEARISH/NEUTRAL]
ðŸ”¹ **Xu hÆ°á»›ng Báº¡c (XAG/USD):** [BULLISH/BEARISH/NEUTRAL]

**LÃ½ do:**
[Giáº£i thÃ­ch ngáº¯n gá»n 3-5 Ä‘iá»ƒm chÃ­nh]

**Khuyáº¿n nghá»‹:**
[Gá»£i Ã½ hÃ nh Ä‘á»™ng: Mua/BÃ¡n/Quan sÃ¡t]

âš ï¸ *ÄÃ¢y lÃ  phÃ¢n tÃ­ch tham kháº£o, khÃ´ng pháº£i tÆ° váº¥n Ä‘áº§u tÆ°.*
"""


async def get_model_and_formatter_with_fallback():
    """
    Try to get model with automatic fallback if primary fails.
    Priority: Perplexity -> Gemini -> GLM (ZhipuAI) -> OpenAI
    
    Note: Perplexity is prioritized because Gemini free tier often has quota issues.
    """
    errors = []
    
    # Priority 1: Try Perplexity first (more reliable for free tier)
    if PERPLEXITY_API_KEY:
        try:
            print("[INFO] Trying Perplexity API...")
            # Use OpenAI client directly with Perplexity base_url
            perplexity_client = OpenAI(
                api_key=PERPLEXITY_API_KEY,
                base_url="https://api.perplexity.ai"
            )
            # Test call to verify API is working
            test_response = perplexity_client.chat.completions.create(
                model="sonar",
                messages=[{"role": "user", "content": "hi"}],
                max_tokens=10
            )
            if test_response.choices:
                print("[INFO] Perplexity API test passed âœ“")
                # Create AgentScope model for use in agents
                model = OpenAIChatModel(
                    model_name="sonar",
                    api_key=PERPLEXITY_API_KEY,
                    client_kwargs={"base_url": "https://api.perplexity.ai"},
                )
                formatter = OpenAIChatFormatter()
                return model, formatter, "Perplexity"
        except Exception as e:
            errors.append(f"Perplexity: {e}")
            print(f"[WARN] Perplexity failed: {e}")
    
    # Priority 2: Fallback to Gemini
    if GEMINI_API_KEY:
        try:
            print("[INFO] Trying Gemini API...")
            model = GeminiChatModel(
                model_name="gemini-2.0-flash",
                api_key=GEMINI_API_KEY,
            )
            formatter = GeminiChatFormatter()
            # Test call to verify API is working using Msg object
            test_msg = Msg(name="user", content="hi", role="user")
            await model(test_msg)
            print("[INFO] Gemini API test passed âœ“")
            return model, formatter, "Gemini"
        except Exception as e:
            errors.append(f"Gemini: {e}")
            print(f"[WARN] Gemini failed: {e}")

    # Priority 3: Fallback to GLM (ZhipuAI - uses OpenAI-compatible API)
    if GLM_API_KEY:
        try:
            print("[INFO] Trying ZhipuAI GLM API (OpenAI-compatible)...")
            model = OpenAIChatModel(
                model_name="glm-4-air",  # Use glm-4-air instead of glm-4-flash
                api_key=GLM_API_KEY,
                client_kwargs={"base_url": "https://open.bigmodel.cn/api/paas/v4/"},
            )
            formatter = OpenAIChatFormatter()
            # Test call to verify GLM API is working
            test_msg = Msg(name="user", content="hi", role="user")
            await model(test_msg)
            print("[INFO] GLM API test passed âœ“")
            return model, formatter, "GLM"
        except Exception as e:
            errors.append(f"GLM: {e}")
            print(f"[WARN] GLM failed: {e}")
    
    # Priority 4: Fallback to OpenAI
    if OPENAI_API_KEY:
        try:
            print("[INFO] Trying OpenAI API...")
            model = OpenAIChatModel(
                model_name="gpt-4o-mini",
                api_key=OPENAI_API_KEY,
            )
            formatter = OpenAIChatFormatter()
            return model, formatter, "OpenAI"
        except Exception as e:
            errors.append(f"OpenAI: {e}")
            print(f"[WARN] OpenAI failed: {e}")
    
    raise ValueError(f"All LLM APIs failed. Errors: {errors}")


async def call_agent_with_retry(agent, input_msg, agent_name: str, max_retries: int = MAX_RETRIES):
    """
    Call an agent with retry logic for rate limit handling.
    
    Args:
        agent: The agent to call
        input_msg: Input message
        agent_name: Name of the agent (for logging)
        max_retries: Maximum number of retries
        
    Returns:
        Agent response content as string
    """
    for attempt in range(max_retries):
        try:
            response = await agent(input_msg)
            content = response.get_text_content() if hasattr(response, 'get_text_content') else str(response.content)
            return content
        except Exception as e:
            error_str = str(e).lower()
            is_rate_limit = "429" in error_str or "rate" in error_str or "quota" in error_str
            
            if is_rate_limit and attempt < max_retries - 1:
                wait_time = RETRY_DELAY_SECONDS * (attempt + 1) * 2  # Exponential backoff
                print(f"[WARN] {agent_name} rate limited (attempt {attempt + 1}/{max_retries}), waiting {wait_time}s...")
                await asyncio.sleep(wait_time)
            else:
                raise e
    
    raise Exception(f"{agent_name} failed after {max_retries} attempts")


async def run_analysis_async(query: str = "gold silver price news") -> str:
    """
    Run the full analysis pipeline (async version) with rate limit handling.

    Args:
        query: Search query for news

    Returns:
        Final analysis report as string
    """
    print(f"[INFO] Starting analysis pipeline with query: {query}")

    # Step 1: Search for news from all sources (News + Twitter)
    news_items = search_all_sources(query, num_news=8, num_tweets=5)

    if not news_items:
        return "âŒ KhÃ´ng tÃ¬m tháº¥y tin tá»©c nÃ o. Vui lÃ²ng thá»­ láº¡i sau."

    # Format news for agent
    news_text = "\n\n".join([
        f"ðŸ“° {item['title']}\n"
        f"   Nguá»“n: {item['source']} | {item['date']}\n"
        f"   {item['snippet']}"
        for item in news_items[:12]  # TÄƒng lÃªn 12 Ä‘á»ƒ bao gá»“m cáº£ tweets
    ])

    # Step 2: Initialize AgentScope
    print("[INFO] Initializing AgentScope...")
    agentscope.init(project="GoldSilverIntelligence", name="analysis")

    # Step 3: Get model and formatter with fallback support
    model, formatter, provider = await get_model_and_formatter_with_fallback()
    print(f"[INFO] Using {provider} as LLM provider")

    # Step 4: Create NewsHunter Agent
    print("[INFO] Creating NewsHunter agent...")
    news_hunter = ReActAgent(
        name="NewsHunter",
        sys_prompt=NEWS_HUNTER_PROMPT,
        model=model,
        memory=InMemoryMemory(),
        formatter=formatter,
        toolkit=Toolkit(),
    )

    # Step 5: Create MarketAnalyst Agent
    print("[INFO] Creating MarketAnalyst agent...")
    market_analyst = ReActAgent(
        name="MarketAnalyst",
        sys_prompt=MARKET_ANALYST_PROMPT,
        model=model,
        memory=InMemoryMemory(),
        formatter=formatter,
        toolkit=Toolkit(),
    )

    # Step 6: NewsHunter filters important news (with retry)
    print("[INFO] NewsHunter analyzing news...")
    hunter_input = Msg(
        name="user",
        content=f"PhÃ¢n tÃ­ch vÃ  lá»c cÃ¡c tin tá»©c sau:\n\n{news_text}",
        role="user"
    )
    hunter_content = await call_agent_with_retry(news_hunter, hunter_input, "NewsHunter")

    # Step 7: MarketAnalyst provides insights (with retry)
    print("[INFO] MarketAnalyst generating report...")
    analyst_input = Msg(
        name="NewsHunter",
        content=f"Dá»±a trÃªn cÃ¡c tin tá»©c Ä‘Ã£ lá»c sau Ä‘Ã¢y, hÃ£y phÃ¢n tÃ­ch xu hÆ°á»›ng giÃ¡ VÃ ng/Báº¡c:\n\n{hunter_content}",
        role="user"
    )
    analyst_content = await call_agent_with_retry(market_analyst, analyst_input, "MarketAnalyst")

    # Combine reports
    final_report = f"ðŸ¤– *Powered by {provider}*\n\n{hunter_content}\n\n---\n\n{analyst_content}"

    print("[INFO] Analysis pipeline completed.")
    return final_report


def run_analysis_pipeline(query: str = "gold silver price news") -> str:
    """
    Run the full analysis pipeline (sync wrapper).
    
    Args:
        query: Search query for news

    Returns:
        Final analysis report as string
    """
    return asyncio.run(run_analysis_async(query))
