"""
Gold-Silver-Intelligence Agents Module
Supports: Z.AI GLM (primary via OpenAI SDK), Gemini (fallback)
Includes: Rate limit handling with retry logic
"""
import os
import time
import asyncio
import requests
from openai import OpenAI
import agentscope
from agentscope.agent import ReActAgent
from agentscope.message import Msg
from agentscope.model import GeminiChatModel
from agentscope.formatter import GeminiChatFormatter
from agentscope.memory import InMemoryMemory
from agentscope.tool import Toolkit

from src.config import SERPER_API_KEY, GEMINI_API_KEY, ZAI_API_KEY


# === Rate Limit Configuration ===
MAX_RETRIES = 3
RETRY_DELAY_SECONDS = 30


def search_news(query: str, num_results: int = 10) -> list:
    """
    Search for news using Serper API with retry logic.
    """
    if not SERPER_API_KEY:
        print("[ERROR] SERPER_API_KEY not configured.")
        return []

    url = "https://google.serper.dev/news"
    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "q": query,
        "num": num_results,
        "tbs": "qdr:d"
    }

    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=15)
            
            if response.status_code in [429, 503]:
                if attempt < MAX_RETRIES - 1:
                    wait_time = RETRY_DELAY_SECONDS
                    print(f"[WARN] Rate limited (attempt {attempt + 1}/{MAX_RETRIES}), waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"[ERROR] Rate limit exceeded after {MAX_RETRIES} attempts")
                    return []
            
            response.raise_for_status()
            data = response.json()

            news = []
            for item in data.get("news", []):
                news.append({
                    "title": item.get("title", ""),
                    "link": item.get("link", ""),
                    "snippet": item.get("snippet", ""),
                    "source": item.get("source", ""),
                    "date": item.get("date", "")
                })
            return news

        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                print(f"[WARN] Request failed (attempt {attempt + 1}/{MAX_RETRIES}): {e}")
                time.sleep(RETRY_DELAY_SECONDS)
            else:
                print(f"[ERROR] Serper API request failed after {MAX_RETRIES} attempts: {e}")
                return []
    
    return []


# === Z.AI GLM via OpenAI SDK ===

def get_zai_client():
    """
    Get Z.AI client using OpenAI SDK with base_url.
    """
    if not ZAI_API_KEY:
        raise ValueError("ZAI_API_KEY not configured")
    
    client = OpenAI(
        api_key=ZAI_API_KEY,
        base_url="https://api.z.ai/api/paas/v4/"  # Z.AI endpoint
    )
    return client


def call_zai_glm(messages: list, system_prompt: str = "") -> str:
    """
    Call Z.AI GLM API using OpenAI SDK.
    
    Args:
        messages: List of message dicts with 'role' and 'content'
        system_prompt: System prompt for the model
        
    Returns:
        Response text from the model
    """
    client = get_zai_client()
    
    # Build messages with system prompt
    api_messages = []
    if system_prompt:
        api_messages.append({"role": "system", "content": system_prompt})
    api_messages.extend(messages)
    
    for attempt in range(MAX_RETRIES):
        try:
            print(f"[DEBUG] Calling Z.AI GLM API via OpenAI SDK...")
            
            response = client.chat.completions.create(
                model="glm-4.7",
                messages=api_messages,
                temperature=0.7,
            )
            
            content = response.choices[0].message.content
            print(f"[DEBUG] Z.AI response received successfully")
            return content
            
        except Exception as e:
            error_str = str(e).lower()
            is_rate_limit = "429" in error_str or "rate" in error_str or "quota" in error_str
            
            if is_rate_limit and attempt < MAX_RETRIES - 1:
                wait_time = RETRY_DELAY_SECONDS * (attempt + 1)
                print(f"[WARN] Z.AI rate limited (attempt {attempt + 1}/{MAX_RETRIES}), waiting {wait_time}s...")
                time.sleep(wait_time)
            else:
                print(f"[ERROR] Z.AI API error: {e}")
                raise e
    
    raise Exception("Z.AI API failed after all retries")


# === Agent System Prompts ===

NEWS_HUNTER_PROMPT = """B·∫°n l√† NewsHunter - chuy√™n gia thu th·∫≠p v√† l·ªçc tin t·ª©c th·ªã tr∆∞·ªùng V√†ng/B·∫°c.

NHI·ªÜM V·ª§:
1. Ph√¢n t√≠ch c√°c tin t·ª©c ƒë∆∞·ª£c cung c·∫•p
2. L·ªçc ra c√°c tin quan tr·ªçng li√™n quan ƒë·∫øn:
   - Ch√≠nh s√°ch l√£i su·∫•t Fed/FOMC
   - Chi·∫øn tranh, xung ƒë·ªôt ƒë·ªãa ch√≠nh tr·ªã
   - Ch·ªâ s·ªë DXY (USD Index)
   - L·∫°m ph√°t, CPI, vi·ªác l√†m M·ªπ
   - Ch√≠nh s√°ch ti·ªÅn t·ªá c√°c ng√¢n h√†ng trung ∆∞∆°ng l·ªõn

OUTPUT FORMAT:
üì∞ **TIN T·ª®C QUAN TR·ªåNG**

1. [Ti√™u ƒë·ªÅ tin 1]
   - Ngu·ªìn: [source]
   - T√≥m t·∫Øt: [2-3 c√¢u t√≥m t·∫Øt]

2. [Ti√™u ƒë·ªÅ tin 2]
   ...

N·∫øu kh√¥ng c√≥ tin quan tr·ªçng, tr·∫£ v·ªÅ: "Kh√¥ng c√≥ tin ƒë√°ng ch√∫ √Ω trong 24h qua."
"""

MARKET_ANALYST_PROMPT = """B·∫°n l√† MarketAnalyst - chuy√™n gia ph√¢n t√≠ch t√°c ƒë·ªông tin t·ª©c l√™n gi√° V√†ng/B·∫°c.

NHI·ªÜM V·ª§:
D·ª±a tr√™n tin t·ª©c ƒë∆∞·ª£c cung c·∫•p, ph√¢n t√≠ch xu h∆∞·ªõng gi√° V√†ng/B·∫°c.

PH∆Ø∆†NG PH√ÅP PH√ÇN T√çCH:
- Fed hawkish (tƒÉng l√£i su·∫•t) ‚Üí Bearish cho V√†ng/B·∫°c
- Fed dovish (gi·ªØ/gi·∫£m l√£i su·∫•t) ‚Üí Bullish cho V√†ng/B·∫°c
- DXY tƒÉng ‚Üí Bearish cho V√†ng/B·∫°c
- DXY gi·∫£m ‚Üí Bullish cho V√†ng/B·∫°c
- B·∫•t ·ªïn ƒë·ªãa ch√≠nh tr·ªã ‚Üí Bullish (safe haven)
- L·∫°m ph√°t cao ‚Üí Bullish (hedge)

OUTPUT FORMAT:
üìä **PH√ÇN T√çCH TH·ªä TR∆Ø·ªúNG V√ÄNG/B·∫†C**

üîπ **Xu h∆∞·ªõng V√†ng (XAU/USD):** [BULLISH/BEARISH/NEUTRAL]
üîπ **Xu h∆∞·ªõng B·∫°c (XAG/USD):** [BULLISH/BEARISH/NEUTRAL]

**L√Ω do:**
[Gi·∫£i th√≠ch ng·∫Øn g·ªçn 3-5 ƒëi·ªÉm ch√≠nh]

**Khuy·∫øn ngh·ªã:**
[G·ª£i √Ω h√†nh ƒë·ªông: Mua/B√°n/Quan s√°t]

‚ö†Ô∏è *ƒê√¢y l√† ph√¢n t√≠ch tham kh·∫£o, kh√¥ng ph·∫£i t∆∞ v·∫•n ƒë·∫ßu t∆∞.*
"""


def run_analysis_with_zai(query: str = "gold silver price news") -> str:
    """
    Run analysis pipeline using Z.AI GLM API.
    """
    print(f"[INFO] Starting analysis pipeline with query: {query}")

    # Step 1: Search for news
    print("[INFO] Fetching news from Serper API...")
    news_items = search_news(query)

    if not news_items:
        return "‚ùå Kh√¥ng t√¨m th·∫•y tin t·ª©c n√†o. Vui l√≤ng th·ª≠ l·∫°i sau."

    # Format news
    news_text = "\n\n".join([
        f"üì∞ {item['title']}\n"
        f"   Ngu·ªìn: {item['source']} | {item['date']}\n"
        f"   {item['snippet']}"
        for item in news_items[:8]
    ])

    print(f"[INFO] Found {len(news_items)} news articles.")

    # Step 2: NewsHunter analyzes news
    print("[INFO] NewsHunter analyzing news (via Z.AI GLM)...")
    hunter_messages = [{"role": "user", "content": f"Ph√¢n t√≠ch v√† l·ªçc c√°c tin t·ª©c sau:\n\n{news_text}"}]
    hunter_content = call_zai_glm(hunter_messages, NEWS_HUNTER_PROMPT)

    # Step 3: MarketAnalyst provides insights
    print("[INFO] MarketAnalyst generating report (via Z.AI GLM)...")
    analyst_messages = [{"role": "user", "content": f"D·ª±a tr√™n c√°c tin t·ª©c ƒë√£ l·ªçc sau ƒë√¢y, h√£y ph√¢n t√≠ch xu h∆∞·ªõng gi√° V√†ng/B·∫°c:\n\n{hunter_content}"}]
    analyst_content = call_zai_glm(analyst_messages, MARKET_ANALYST_PROMPT)

    # Combine reports
    final_report = f"ü§ñ *Powered by Z.AI GLM-4.7*\n\n{hunter_content}\n\n---\n\n{analyst_content}"

    print("[INFO] Analysis pipeline completed.")
    return final_report


async def run_analysis_with_gemini(query: str = "gold silver price news") -> str:
    """
    Run analysis pipeline using Gemini via AgentScope.
    """
    print(f"[INFO] Starting analysis pipeline with query: {query}")

    # Step 1: Search for news
    print("[INFO] Fetching news from Serper API...")
    news_items = search_news(query)

    if not news_items:
        return "‚ùå Kh√¥ng t√¨m th·∫•y tin t·ª©c n√†o. Vui l√≤ng th·ª≠ l·∫°i sau."

    # Format news
    news_text = "\n\n".join([
        f"üì∞ {item['title']}\n"
        f"   Ngu·ªìn: {item['source']} | {item['date']}\n"
        f"   {item['snippet']}"
        for item in news_items[:8]
    ])

    print(f"[INFO] Found {len(news_items)} news articles.")

    # Initialize AgentScope and use Gemini
    print("[INFO] Initializing AgentScope with Gemini...")
    agentscope.init(project="GoldSilverIntelligence", name="analysis")
    
    model = GeminiChatModel(
        model_name="gemini-2.0-flash",
        api_key=GEMINI_API_KEY,
    )
    formatter = GeminiChatFormatter()
    
    # Create agents
    news_hunter = ReActAgent(
        name="NewsHunter",
        sys_prompt=NEWS_HUNTER_PROMPT,
        model=model,
        memory=InMemoryMemory(),
        formatter=formatter,
        toolkit=Toolkit(),
    )
    
    market_analyst = ReActAgent(
        name="MarketAnalyst",
        sys_prompt=MARKET_ANALYST_PROMPT,
        model=model,
        memory=InMemoryMemory(),
        formatter=formatter,
        toolkit=Toolkit(),
    )
    
    # Run agents
    hunter_input = Msg(name="user", content=f"Ph√¢n t√≠ch v√† l·ªçc c√°c tin t·ª©c sau:\n\n{news_text}", role="user")
    hunter_response = await news_hunter(hunter_input)
    hunter_content = hunter_response.get_text_content() if hasattr(hunter_response, 'get_text_content') else str(hunter_response.content)
    
    analyst_input = Msg(name="NewsHunter", content=f"D·ª±a tr√™n c√°c tin t·ª©c ƒë√£ l·ªçc sau ƒë√¢y, h√£y ph√¢n t√≠ch xu h∆∞·ªõng gi√° V√†ng/B·∫°c:\n\n{hunter_content}", role="user")
    analyst_response = await market_analyst(analyst_input)
    analyst_content = analyst_response.get_text_content() if hasattr(analyst_response, 'get_text_content') else str(analyst_response.content)
    
    final_report = f"ü§ñ *Powered by Gemini*\n\n{hunter_content}\n\n---\n\n{analyst_content}"
    print("[INFO] Analysis pipeline completed.")
    return final_report


def run_analysis_pipeline(query: str = "gold silver price news") -> str:
    """
    Run the full analysis pipeline with fallback.
    Priority: Z.AI GLM -> Gemini
    """
    # Try Z.AI GLM first
    if ZAI_API_KEY:
        try:
            print("[INFO] Using Z.AI GLM API (Priority 1) via OpenAI SDK...")
            return run_analysis_with_zai(query)
        except Exception as e:
            print(f"[WARN] Z.AI GLM failed: {e}")
    
    # Fallback to Gemini
    if GEMINI_API_KEY:
        try:
            print("[INFO] Using Gemini API (Fallback)...")
            return asyncio.run(run_analysis_with_gemini(query))
        except Exception as e:
            print(f"[WARN] Gemini failed: {e}")
    
    return "‚ùå Kh√¥ng c√≥ LLM API kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra ZAI_API_KEY ho·∫∑c GEMINI_API_KEY."
