"""
Gold-Silver-Intelligence Agents Module
Rewritten for AgentScope 1.0+ API (async-based).
Supports: Gemini (via AgentScope), ZhipuAI GLM (direct API)
Includes: Rate limit handling with retry logic
"""
import os
import time
import asyncio
import requests
import agentscope
from agentscope.agent import ReActAgent
from agentscope.message import Msg
from agentscope.model import GeminiChatModel, OpenAIChatModel
from agentscope.formatter import GeminiChatFormatter, OpenAIChatFormatter
from agentscope.memory import InMemoryMemory
from agentscope.tool import Toolkit

from src.config import SERPER_API_KEY, GEMINI_API_KEY, OPENAI_API_KEY, GLM_API_KEY


# === Rate Limit Configuration ===
MAX_RETRIES = 3
RETRY_DELAY_SECONDS = 5
RATE_LIMIT_CODES = [429, 503]


def search_news(query: str, num_results: int = 10) -> list:
    """
    Search for news using Serper API with retry logic.
    """
    if not SERPER_API_KEY:
        print("[ERROR] SERPER_API_KEY not configured.")
        return []

    url = "https://google.serper.dev/news"
    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "q": query,
        "num": num_results,
        "tbs": "qdr:d"
    }

    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=15)
            
            if response.status_code in RATE_LIMIT_CODES:
                if attempt < MAX_RETRIES - 1:
                    wait_time = RETRY_DELAY_SECONDS * (attempt + 1)
                    print(f"[WARN] Rate limited (attempt {attempt + 1}/{MAX_RETRIES}), waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"[ERROR] Rate limit exceeded after {MAX_RETRIES} attempts")
                    return []
            
            response.raise_for_status()
            data = response.json()

            news = []
            for item in data.get("news", []):
                news.append({
                    "title": item.get("title", ""),
                    "link": item.get("link", ""),
                    "snippet": item.get("snippet", ""),
                    "source": item.get("source", ""),
                    "date": item.get("date", "")
                })
            return news

        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                print(f"[WARN] Request failed (attempt {attempt + 1}/{MAX_RETRIES}): {e}")
                time.sleep(RETRY_DELAY_SECONDS)
            else:
                print(f"[ERROR] Serper API request failed after {MAX_RETRIES} attempts: {e}")
                return []
    
    return []


# === Direct ZhipuAI API Integration ===

def call_zhipuai_chat(messages: list, system_prompt: str = "") -> str:
    """
    Call ZhipuAI GLM API directly (bypassing AgentScope).
    
    Args:
        messages: List of message dicts with 'role' and 'content'
        system_prompt: System prompt for the model
        
    Returns:
        Response text from the model
    """
    if not GLM_API_KEY:
        raise ValueError("GLM_API_KEY not configured")
    
    url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    headers = {
        "Authorization": f"Bearer {GLM_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # Build messages with system prompt
    api_messages = []
    if system_prompt:
        api_messages.append({"role": "system", "content": system_prompt})
    api_messages.extend(messages)
    
    payload = {
        "model": "glm-4-flash",
        "messages": api_messages,
        "temperature": 0.7,
        "max_tokens": 2048
    }
    
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=60)
            
            if response.status_code in RATE_LIMIT_CODES:
                if attempt < MAX_RETRIES - 1:
                    wait_time = RETRY_DELAY_SECONDS * (attempt + 1) * 2
                    print(f"[WARN] GLM rate limited (attempt {attempt + 1}/{MAX_RETRIES}), waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
            
            response.raise_for_status()
            data = response.json()
            
            return data["choices"][0]["message"]["content"]
            
        except requests.exceptions.RequestException as e:
            if attempt < MAX_RETRIES - 1:
                print(f"[WARN] GLM request failed (attempt {attempt + 1}/{MAX_RETRIES}): {e}")
                time.sleep(RETRY_DELAY_SECONDS)
            else:
                raise Exception(f"GLM API failed after {MAX_RETRIES} attempts: {e}")
    
    raise Exception("GLM API failed")


# === Agent System Prompts ===

NEWS_HUNTER_PROMPT = """B·∫°n l√† NewsHunter - chuy√™n gia thu th·∫≠p v√† l·ªçc tin t·ª©c th·ªã tr∆∞·ªùng V√†ng/B·∫°c.

NHI·ªÜM V·ª§:
1. Ph√¢n t√≠ch c√°c tin t·ª©c ƒë∆∞·ª£c cung c·∫•p
2. L·ªçc ra c√°c tin quan tr·ªçng li√™n quan ƒë·∫øn:
   - Ch√≠nh s√°ch l√£i su·∫•t Fed/FOMC
   - Chi·∫øn tranh, xung ƒë·ªôt ƒë·ªãa ch√≠nh tr·ªã
   - Ch·ªâ s·ªë DXY (USD Index)
   - L·∫°m ph√°t, CPI, vi·ªác l√†m M·ªπ
   - Ch√≠nh s√°ch ti·ªÅn t·ªá c√°c ng√¢n h√†ng trung ∆∞∆°ng l·ªõn

OUTPUT FORMAT:
üì∞ **TIN T·ª®C QUAN TR·ªåNG**

1. [Ti√™u ƒë·ªÅ tin 1]
   - Ngu·ªìn: [source]
   - T√≥m t·∫Øt: [2-3 c√¢u t√≥m t·∫Øt]

2. [Ti√™u ƒë·ªÅ tin 2]
   ...

N·∫øu kh√¥ng c√≥ tin quan tr·ªçng, tr·∫£ v·ªÅ: "Kh√¥ng c√≥ tin ƒë√°ng ch√∫ √Ω trong 24h qua."
"""

MARKET_ANALYST_PROMPT = """B·∫°n l√† MarketAnalyst - chuy√™n gia ph√¢n t√≠ch t√°c ƒë·ªông tin t·ª©c l√™n gi√° V√†ng/B·∫°c.

NHI·ªÜM V·ª§:
D·ª±a tr√™n tin t·ª©c ƒë∆∞·ª£c cung c·∫•p, ph√¢n t√≠ch xu h∆∞·ªõng gi√° V√†ng/B·∫°c.

PH∆Ø∆†NG PH√ÅP PH√ÇN T√çCH:
- Fed hawkish (tƒÉng l√£i su·∫•t) ‚Üí Bearish cho V√†ng/B·∫°c
- Fed dovish (gi·ªØ/gi·∫£m l√£i su·∫•t) ‚Üí Bullish cho V√†ng/B·∫°c
- DXY tƒÉng ‚Üí Bearish cho V√†ng/B·∫°c
- DXY gi·∫£m ‚Üí Bullish cho V√†ng/B·∫°c
- B·∫•t ·ªïn ƒë·ªãa ch√≠nh tr·ªã ‚Üí Bullish (safe haven)
- L·∫°m ph√°t cao ‚Üí Bullish (hedge)

OUTPUT FORMAT:
üìä **PH√ÇN T√çCH TH·ªä TR∆Ø·ªúNG V√ÄNG/B·∫†C**

üîπ **Xu h∆∞·ªõng V√†ng (XAU/USD):** [BULLISH/BEARISH/NEUTRAL]
üîπ **Xu h∆∞·ªõng B·∫°c (XAG/USD):** [BULLISH/BEARISH/NEUTRAL]

**L√Ω do:**
[Gi·∫£i th√≠ch ng·∫Øn g·ªçn 3-5 ƒëi·ªÉm ch√≠nh]

**Khuy·∫øn ngh·ªã:**
[G·ª£i √Ω h√†nh ƒë·ªông: Mua/B√°n/Quan s√°t]

‚ö†Ô∏è *ƒê√¢y l√† ph√¢n t√≠ch tham kh·∫£o, kh√¥ng ph·∫£i t∆∞ v·∫•n ƒë·∫ßu t∆∞.*
"""


def run_analysis_with_glm(query: str = "gold silver price news") -> str:
    """
    Run analysis pipeline using direct ZhipuAI GLM API calls.
    """
    print(f"[INFO] Starting analysis pipeline with query: {query}")

    # Step 1: Search for news
    print("[INFO] Fetching news from Serper API...")
    news_items = search_news(query)

    if not news_items:
        return "‚ùå Kh√¥ng t√¨m th·∫•y tin t·ª©c n√†o. Vui l√≤ng th·ª≠ l·∫°i sau."

    # Format news
    news_text = "\n\n".join([
        f"üì∞ {item['title']}\n"
        f"   Ngu·ªìn: {item['source']} | {item['date']}\n"
        f"   {item['snippet']}"
        for item in news_items[:8]
    ])

    print(f"[INFO] Found {len(news_items)} news articles.")

    # Step 2: NewsHunter analyzes news
    print("[INFO] NewsHunter analyzing news (via GLM direct API)...")
    hunter_messages = [{"role": "user", "content": f"Ph√¢n t√≠ch v√† l·ªçc c√°c tin t·ª©c sau:\n\n{news_text}"}]
    hunter_content = call_zhipuai_chat(hunter_messages, NEWS_HUNTER_PROMPT)

    # Step 3: MarketAnalyst provides insights
    print("[INFO] MarketAnalyst generating report (via GLM direct API)...")
    analyst_messages = [{"role": "user", "content": f"D·ª±a tr√™n c√°c tin t·ª©c ƒë√£ l·ªçc sau ƒë√¢y, h√£y ph√¢n t√≠ch xu h∆∞·ªõng gi√° V√†ng/B·∫°c:\n\n{hunter_content}"}]
    analyst_content = call_zhipuai_chat(analyst_messages, MARKET_ANALYST_PROMPT)

    # Combine reports
    final_report = f"ü§ñ *Powered by ZhipuAI GLM*\n\n{hunter_content}\n\n---\n\n{analyst_content}"

    print("[INFO] Analysis pipeline completed.")
    return final_report


def run_analysis_with_gemini(query: str = "gold silver price news") -> str:
    """
    Run analysis pipeline using Gemini via AgentScope.
    """
    print(f"[INFO] Starting analysis pipeline with query: {query}")

    # Step 1: Search for news
    print("[INFO] Fetching news from Serper API...")
    news_items = search_news(query)

    if not news_items:
        return "‚ùå Kh√¥ng t√¨m th·∫•y tin t·ª©c n√†o. Vui l√≤ng th·ª≠ l·∫°i sau."

    # Format news
    news_text = "\n\n".join([
        f"üì∞ {item['title']}\n"
        f"   Ngu·ªìn: {item['source']} | {item['date']}\n"
        f"   {item['snippet']}"
        for item in news_items[:8]
    ])

    print(f"[INFO] Found {len(news_items)} news articles.")

    # Initialize AgentScope and use Gemini
    print("[INFO] Initializing AgentScope with Gemini...")
    agentscope.init(project="GoldSilverIntelligence", name="analysis")
    
    model = GeminiChatModel(
        model_name="gemini-2.0-flash",
        api_key=GEMINI_API_KEY,
    )
    formatter = GeminiChatFormatter()
    
    # Create agents
    news_hunter = ReActAgent(
        name="NewsHunter",
        sys_prompt=NEWS_HUNTER_PROMPT,
        model=model,
        memory=InMemoryMemory(),
        formatter=formatter,
        toolkit=Toolkit(),
    )
    
    market_analyst = ReActAgent(
        name="MarketAnalyst",
        sys_prompt=MARKET_ANALYST_PROMPT,
        model=model,
        memory=InMemoryMemory(),
        formatter=formatter,
        toolkit=Toolkit(),
    )
    
    # Run async pipeline
    async def run_agents():
        hunter_input = Msg(name="user", content=f"Ph√¢n t√≠ch v√† l·ªçc c√°c tin t·ª©c sau:\n\n{news_text}", role="user")
        hunter_response = await news_hunter(hunter_input)
        hunter_content = hunter_response.get_text_content() if hasattr(hunter_response, 'get_text_content') else str(hunter_response.content)
        
        analyst_input = Msg(name="NewsHunter", content=f"D·ª±a tr√™n c√°c tin t·ª©c ƒë√£ l·ªçc sau ƒë√¢y, h√£y ph√¢n t√≠ch xu h∆∞·ªõng gi√° V√†ng/B·∫°c:\n\n{hunter_content}", role="user")
        analyst_response = await market_analyst(analyst_input)
        analyst_content = analyst_response.get_text_content() if hasattr(analyst_response, 'get_text_content') else str(analyst_response.content)
        
        return hunter_content, analyst_content
    
    hunter_content, analyst_content = asyncio.run(run_agents())
    
    final_report = f"ü§ñ *Powered by Gemini*\n\n{hunter_content}\n\n---\n\n{analyst_content}"
    print("[INFO] Analysis pipeline completed.")
    return final_report


def run_analysis_pipeline(query: str = "gold silver price news") -> str:
    """
    Run the full analysis pipeline with fallback.
    Priority: GLM (direct API) -> Gemini (AgentScope)
    """
    # Try GLM first (direct API call)
    if GLM_API_KEY:
        try:
            print("[INFO] Using ZhipuAI GLM (direct API)...")
            return run_analysis_with_glm(query)
        except Exception as e:
            print(f"[WARN] GLM failed: {e}")
    
    # Fallback to Gemini
    if GEMINI_API_KEY:
        try:
            print("[INFO] Using Gemini (AgentScope)...")
            return run_analysis_with_gemini(query)
        except Exception as e:
            print(f"[WARN] Gemini failed: {e}")
    
    return "‚ùå Kh√¥ng c√≥ LLM API kh·∫£ d·ª•ng. Vui l√≤ng ki·ªÉm tra API keys."
